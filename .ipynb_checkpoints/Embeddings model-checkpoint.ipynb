{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.layers import Conv1D, Concatenate,Input, Dense, Embedding, merge, LSTM, concatenate, Flatten, Dropout, Lambda, BatchNormalization\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataAll = pd.read_csv('/Users/ruben.arana/git/beat-bookies/data/combinedData.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE TEAM EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = dataAll.VISITOR_TEAM.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Atlanta': 9,\n",
       " 'Boston': 26,\n",
       " 'Brooklyn': 18,\n",
       " 'Charlotte': 17,\n",
       " 'Chicago': 8,\n",
       " 'Cleveland': 21,\n",
       " 'Dallas': 23,\n",
       " 'Denver': 13,\n",
       " 'Detroit': 14,\n",
       " 'Golden State': 25,\n",
       " 'Houston': 11,\n",
       " 'Indiana': 1,\n",
       " 'L.A. Clippers': 10,\n",
       " 'L.A. Lakers': 4,\n",
       " 'Memphis': 22,\n",
       " 'Miami': 28,\n",
       " 'Milwaukee': 3,\n",
       " 'Minnesota': 15,\n",
       " 'New Orleans': 0,\n",
       " 'New York': 5,\n",
       " 'Orlando': 27,\n",
       " 'Philadelphia': 19,\n",
       " 'Phoenix': 24,\n",
       " 'Portland': 16,\n",
       " 'Sacramento': 6,\n",
       " 'San Antonio': 12,\n",
       " 'Toronto': 7,\n",
       " 'Utah': 20,\n",
       " 'Washington': 2}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create indexes for teams\n",
    "teamId2idx = {o:i for i,o in enumerate(teams)}\n",
    "teamId2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all team nambes for the indexes\n",
    "dataAll.VISITOR_TEAM = dataAll.VISITOR_TEAM.apply(lambda x: teamId2idx[x])\n",
    "dataAll.HOME_TEAM = dataAll.HOME_TEAM.apply(lambda x: teamId2idx[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize params\n",
    "teams_number = dataAll.VISITOR_TEAM.unique().size\n",
    "num_features = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Embedding` call to the Keras 2 API: `Embedding(29, 50, input_length=1, embeddings_regularizer=<keras.reg...)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Embedding` call to the Keras 2 API: `Embedding(29, 50, input_length=1, embeddings_regularizer=<keras.reg...)`\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# Create embeddings\n",
    "home_in = Input(shape=(1,), dtype='int64', name='home_in')\n",
    "u = Embedding(teams_number, num_features, input_length=1, W_regularizer=l2(1e-4))(home_in)\n",
    "visitor_in = Input(shape=(1,), dtype='int64', name='visitor_in')\n",
    "m = Embedding(teams_number, num_features, input_length=1, W_regularizer=l2(1e-4))(visitor_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE TRAINING AND VALIDATION SETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting all data randomly between training and validation\n",
    "# msk = np.random.rand(len(dataAll)) < 0.8\n",
    "# trn = dataAll[msk]\n",
    "# val = dataAll[~msk]\n",
    "\n",
    "# Splitting all data keeping the first ones as training set\n",
    "n = dataAll.shape[0]\n",
    "train_size = 0.8\n",
    "\n",
    "trn = dataAll.iloc[:int(n * train_size)]\n",
    "val = dataAll.iloc[int(n * train_size):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIMPLE MODEL USING EMBEDDING DOT PRODUCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  \n",
      "/usr/local/lib/python3.6/site-packages/keras/legacy/layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n"
     ]
    }
   ],
   "source": [
    "# Creating embedding dot product model\n",
    "x = merge([u, m], mode='dot')\n",
    "x = Flatten()(x)\n",
    "model = Model([home_in, visitor_in], x)\n",
    "model.compile(Adam(0.001), loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "home_in (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "visitor_in (InputLayer)         (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 1, 50)        1450        home_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 1, 50)        1450        visitor_in[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_2 (Merge)                 (None, 1, 1)         0           embedding_5[0][0]                \n",
      "                                                                 embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 1)            0           merge_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,900\n",
      "Trainable params: 2,900\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 960 samples, validate on 241 samples\n",
      "Epoch 1/200\n",
      "960/960 [==============================] - 0s 330us/step - loss: 39325.2630 - val_loss: 38528.7951\n",
      "Epoch 2/200\n",
      "960/960 [==============================] - 0s 26us/step - loss: 39323.7667 - val_loss: 38527.5574\n",
      "Epoch 3/200\n",
      "960/960 [==============================] - 0s 43us/step - loss: 39320.9880 - val_loss: 38523.8821\n",
      "Epoch 4/200\n",
      "960/960 [==============================] - 0s 41us/step - loss: 39314.7292 - val_loss: 38515.2350\n",
      "Epoch 5/200\n",
      "960/960 [==============================] - 0s 41us/step - loss: 39301.7674 - val_loss: 38497.7634\n",
      "Epoch 6/200\n",
      "960/960 [==============================] - 0s 35us/step - loss: 39278.2617 - val_loss: 38467.5755\n",
      "Epoch 7/200\n",
      "960/960 [==============================] - 0s 34us/step - loss: 39240.1451 - val_loss: 38421.2113\n",
      "Epoch 8/200\n",
      "960/960 [==============================] - 0s 53us/step - loss: 39184.3956 - val_loss: 38355.9340\n",
      "Epoch 9/200\n",
      "960/960 [==============================] - 0s 41us/step - loss: 39109.0117 - val_loss: 38270.9730\n",
      "Epoch 10/200\n",
      "960/960 [==============================] - 0s 73us/step - loss: 39013.0068 - val_loss: 38164.5972\n",
      "Epoch 11/200\n",
      "960/960 [==============================] - 0s 34us/step - loss: 38894.9096 - val_loss: 38035.5569\n",
      "Epoch 12/200\n",
      "960/960 [==============================] - 0s 47us/step - loss: 38754.3776 - val_loss: 37885.5299\n",
      "Epoch 13/200\n",
      "960/960 [==============================] - 0s 34us/step - loss: 38592.5396 - val_loss: 37714.2727\n",
      "Epoch 14/200\n",
      "960/960 [==============================] - 0s 54us/step - loss: 38410.3987 - val_loss: 37523.3217\n",
      "Epoch 15/200\n",
      "960/960 [==============================] - 0s 45us/step - loss: 38207.4797 - val_loss: 37313.3378\n",
      "Epoch 16/200\n",
      "960/960 [==============================] - 0s 34us/step - loss: 37986.4310 - val_loss: 37084.9849\n",
      "Epoch 17/200\n",
      "960/960 [==============================] - 0s 53us/step - loss: 37746.9104 - val_loss: 36839.2488\n",
      "Epoch 18/200\n",
      "960/960 [==============================] - 0s 33us/step - loss: 37491.0784 - val_loss: 36576.9789\n",
      "Epoch 19/200\n",
      "960/960 [==============================] - 0s 49us/step - loss: 37218.2005 - val_loss: 36299.6985\n",
      "Epoch 20/200\n",
      "960/960 [==============================] - 0s 27us/step - loss: 36929.6417 - val_loss: 36005.9936\n",
      "Epoch 21/200\n",
      "960/960 [==============================] - 0s 45us/step - loss: 36625.1500 - val_loss: 35697.2146\n",
      "Epoch 22/200\n",
      "960/960 [==============================] - 0s 44us/step - loss: 36306.2208 - val_loss: 35374.8785\n",
      "Epoch 23/200\n",
      "960/960 [==============================] - 0s 38us/step - loss: 35973.1172 - val_loss: 35038.4050\n",
      "Epoch 24/200\n",
      "960/960 [==============================] - 0s 45us/step - loss: 35627.0083 - val_loss: 34689.3183\n",
      "Epoch 25/200\n",
      "960/960 [==============================] - 0s 37us/step - loss: 35266.6977 - val_loss: 34327.4862\n",
      "Epoch 26/200\n",
      "960/960 [==============================] - 0s 45us/step - loss: 34894.4568 - val_loss: 33953.3148\n",
      "Epoch 27/200\n",
      "960/960 [==============================] - 0s 37us/step - loss: 34510.3866 - val_loss: 33566.9453\n",
      "Epoch 28/200\n",
      "960/960 [==============================] - 0s 37us/step - loss: 34112.9750 - val_loss: 33170.0396\n",
      "Epoch 29/200\n",
      "960/960 [==============================] - 0s 47us/step - loss: 33706.4217 - val_loss: 32761.9239\n",
      "Epoch 30/200\n",
      "960/960 [==============================] - 0s 33us/step - loss: 33287.6483 - val_loss: 32344.4135\n",
      "Epoch 31/200\n",
      "960/960 [==============================] - 0s 54us/step - loss: 32860.6815 - val_loss: 31916.6983\n",
      "Epoch 32/200\n",
      "960/960 [==============================] - 0s 24us/step - loss: 32422.3990 - val_loss: 31478.2515\n",
      "Epoch 33/200\n",
      "960/960 [==============================] - 0s 41us/step - loss: 31975.1548 - val_loss: 31032.4984\n",
      "Epoch 34/200\n",
      "960/960 [==============================] - 0s 46us/step - loss: 31519.8518 - val_loss: 30577.7390\n",
      "Epoch 35/200\n",
      "960/960 [==============================] - 0s 42us/step - loss: 31056.1238 - val_loss: 30115.6462\n",
      "Epoch 36/200\n",
      "960/960 [==============================] - 0s 47us/step - loss: 30584.3335 - val_loss: 29647.2184\n",
      "Epoch 37/200\n",
      "960/960 [==============================] - 0s 40us/step - loss: 30106.5148 - val_loss: 29171.9819\n",
      "Epoch 38/200\n",
      "960/960 [==============================] - 0s 38us/step - loss: 29622.0208 - val_loss: 28690.2890\n",
      "Epoch 39/200\n",
      "960/960 [==============================] - 0s 42us/step - loss: 29131.9296 - val_loss: 28203.6111\n",
      "Epoch 40/200\n",
      "960/960 [==============================] - 0s 29us/step - loss: 28636.0283 - val_loss: 27712.2106\n",
      "Epoch 41/200\n",
      "960/960 [==============================] - 0s 55us/step - loss: 28134.7060 - val_loss: 27215.0571\n",
      "Epoch 42/200\n",
      "960/960 [==============================] - 0s 22us/step - loss: 27630.1682 - val_loss: 26715.2208\n",
      "Epoch 43/200\n",
      "960/960 [==============================] - 0s 27us/step - loss: 27122.1962 - val_loss: 26211.1328\n",
      "Epoch 44/200\n",
      "960/960 [==============================] - 0s 50us/step - loss: 26609.1901 - val_loss: 25703.8431\n",
      "Epoch 45/200\n",
      "960/960 [==============================] - 0s 30us/step - loss: 26094.4961 - val_loss: 25194.8953\n",
      "Epoch 46/200\n",
      "960/960 [==============================] - 0s 24us/step - loss: 25577.7711 - val_loss: 24683.6754\n",
      "Epoch 47/200\n",
      "960/960 [==============================] - 0s 39us/step - loss: 25058.5354 - val_loss: 24171.3662\n",
      "Epoch 48/200\n",
      "960/960 [==============================] - 0s 31us/step - loss: 24537.7559 - val_loss: 23657.5235\n",
      "Epoch 49/200\n",
      "960/960 [==============================] - 0s 28us/step - loss: 24017.0199 - val_loss: 23143.2398\n",
      "Epoch 50/200\n",
      "960/960 [==============================] - 0s 57us/step - loss: 23494.0576 - val_loss: 22627.9944\n",
      "Epoch 51/200\n",
      "960/960 [==============================] - 0s 40us/step - loss: 22972.1397 - val_loss: 22112.3135\n",
      "Epoch 52/200\n",
      "960/960 [==============================] - 0s 58us/step - loss: 22449.8051 - val_loss: 21598.1710\n",
      "Epoch 53/200\n",
      "960/960 [==============================] - 0s 47us/step - loss: 21928.5522 - val_loss: 21085.1057\n",
      "Epoch 54/200\n",
      "960/960 [==============================] - 0s 53us/step - loss: 21407.7878 - val_loss: 20574.8645\n",
      "Epoch 55/200\n",
      "960/960 [==============================] - 0s 40us/step - loss: 20891.5687 - val_loss: 20064.4517\n",
      "Epoch 56/200\n",
      "960/960 [==============================] - 0s 45us/step - loss: 20374.1836 - val_loss: 19556.7479\n",
      "Epoch 57/200\n",
      "960/960 [==============================] - 0s 26us/step - loss: 19859.3551 - val_loss: 19050.7611\n",
      "Epoch 58/200\n",
      "960/960 [==============================] - 0s 33us/step - loss: 19348.7260 - val_loss: 18548.4575\n",
      "Epoch 59/200\n",
      "960/960 [==============================] - 0s 30us/step - loss: 18839.5064 - val_loss: 18049.4267\n",
      "Epoch 60/200\n",
      "960/960 [==============================] - 0s 33us/step - loss: 18334.4754 - val_loss: 17556.2564\n",
      "Epoch 61/200\n",
      "960/960 [==============================] - 0s 30us/step - loss: 17834.0061 - val_loss: 17064.8057\n",
      "Epoch 62/200\n",
      "960/960 [==============================] - 0s 32us/step - loss: 17337.6857 - val_loss: 16576.6814\n",
      "Epoch 63/200\n",
      "960/960 [==============================] - 0s 40us/step - loss: 16843.8191 - val_loss: 16095.2034\n",
      "Epoch 64/200\n",
      "960/960 [==============================] - 0s 35us/step - loss: 16359.1039 - val_loss: 15617.7302\n",
      "Epoch 65/200\n",
      "960/960 [==============================] - 0s 26us/step - loss: 15875.4016 - val_loss: 15148.0731\n",
      "Epoch 66/200\n",
      "960/960 [==============================] - 0s 46us/step - loss: 15399.7568 - val_loss: 14684.3452\n",
      "Epoch 67/200\n",
      "960/960 [==============================] - 0s 36us/step - loss: 14929.8293 - val_loss: 14225.7901\n",
      "Epoch 68/200\n",
      "960/960 [==============================] - 0s 51us/step - loss: 14466.1443 - val_loss: 13772.1473\n",
      "Epoch 69/200\n",
      "960/960 [==============================] - 0s 32us/step - loss: 14009.1191 - val_loss: 13325.3839\n",
      "Epoch 70/200\n",
      "960/960 [==============================] - 0s 34us/step - loss: 13557.6698 - val_loss: 12886.5152\n",
      "Epoch 71/200\n",
      "960/960 [==============================] - 0s 46us/step - loss: 13112.8598 - val_loss: 12455.7459\n",
      "Epoch 72/200\n",
      "960/960 [==============================] - 0s 26us/step - loss: 12677.3421 - val_loss: 12029.4054\n",
      "Epoch 73/200\n",
      "960/960 [==============================] - 0s 49us/step - loss: 12247.5286 - val_loss: 11611.4755\n",
      "Epoch 74/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "960/960 [==============================] - 0s 28us/step - loss: 11824.6535 - val_loss: 11201.9527\n",
      "Epoch 75/200\n",
      "960/960 [==============================] - 0s 29us/step - loss: 11411.4204 - val_loss: 10799.9222\n",
      "Epoch 76/200\n",
      "960/960 [==============================] - 0s 47us/step - loss: 11003.8914 - val_loss: 10404.7816\n",
      "Epoch 77/200\n",
      "960/960 [==============================] - 0s 36us/step - loss: 10605.3621 - val_loss: 10018.7938\n",
      "Epoch 78/200\n",
      "960/960 [==============================] - 0s 34us/step - loss: 10215.4863 - val_loss: 9639.9675\n",
      "Epoch 79/200\n",
      "960/960 [==============================] - 0s 33us/step - loss: 9832.9430 - val_loss: 9270.3293\n",
      "Epoch 80/200\n",
      "960/960 [==============================] - 0s 30us/step - loss: 9460.1794 - val_loss: 8907.6559\n",
      "Epoch 81/200\n",
      "960/960 [==============================] - 0s 28us/step - loss: 9094.4761 - val_loss: 8556.2189\n",
      "Epoch 82/200\n",
      "960/960 [==============================] - 0s 35us/step - loss: 8739.2470 - val_loss: 8211.1158\n",
      "Epoch 83/200\n",
      "960/960 [==============================] - 0s 26us/step - loss: 8390.8965 - val_loss: 7875.8101\n",
      "Epoch 84/200\n",
      "960/960 [==============================] - 0s 27us/step - loss: 8052.4647 - val_loss: 7549.4601\n",
      "Epoch 85/200\n",
      "960/960 [==============================] - 0s 28us/step - loss: 7721.4737 - val_loss: 7232.6896\n",
      "Epoch 86/200\n",
      "960/960 [==============================] - 0s 37us/step - loss: 7401.8187 - val_loss: 6923.4558\n",
      "Epoch 87/200\n",
      "960/960 [==============================] - 0s 32us/step - loss: 7089.5308 - val_loss: 6624.0624\n",
      "Epoch 88/200\n",
      "960/960 [==============================] - 0s 35us/step - loss: 6786.1816 - val_loss: 6332.2510\n",
      "Epoch 89/200\n",
      "960/960 [==============================] - 0s 34us/step - loss: 6491.5324 - val_loss: 6050.8747\n",
      "Epoch 90/200\n",
      "960/960 [==============================] - 0s 36us/step - loss: 6206.2755 - val_loss: 5778.3036\n",
      "Epoch 91/200\n",
      "960/960 [==============================] - 0s 47us/step - loss: 5931.8028 - val_loss: 5510.7773\n",
      "Epoch 92/200\n",
      "960/960 [==============================] - 0s 37us/step - loss: 5662.2419 - val_loss: 5255.3689\n",
      "Epoch 93/200\n",
      "960/960 [==============================] - 0s 29us/step - loss: 5403.6995 - val_loss: 5008.9409\n",
      "Epoch 94/200\n",
      "960/960 [==============================] - 0s 41us/step - loss: 5154.7383 - val_loss: 4769.8330\n",
      "Epoch 95/200\n",
      "960/960 [==============================] - 0s 22us/step - loss: 4912.5756 - val_loss: 4540.0422\n",
      "Epoch 96/200\n",
      "960/960 [==============================] - 0s 26us/step - loss: 4680.7951 - val_loss: 4318.7592\n",
      "Epoch 97/200\n",
      "960/960 [==============================] - 0s 35us/step - loss: 4455.7619 - val_loss: 4106.0155\n",
      "Epoch 98/200\n",
      "960/960 [==============================] - 0s 24us/step - loss: 4240.9768 - val_loss: 3900.1224\n",
      "Epoch 99/200\n",
      "960/960 [==============================] - ETA: 0s - loss: 3697.86 - 0s 25us/step - loss: 4032.5424 - val_loss: 3702.2417\n",
      "Epoch 100/200\n",
      "960/960 [==============================] - 0s 27us/step - loss: 3833.3409 - val_loss: 3513.2823\n",
      "Epoch 101/200\n",
      "960/960 [==============================] - 0s 35us/step - loss: 3641.3847 - val_loss: 3333.1315\n",
      "Epoch 102/200\n",
      "960/960 [==============================] - 0s 29us/step - loss: 3457.9656 - val_loss: 3161.1691\n",
      "Epoch 103/200\n",
      "960/960 [==============================] - 0s 26us/step - loss: 3283.0151 - val_loss: 2993.6926\n",
      "Epoch 104/200\n",
      "960/960 [==============================] - 0s 39us/step - loss: 3114.0292 - val_loss: 2835.6551\n",
      "Epoch 105/200\n",
      "960/960 [==============================] - 0s 26us/step - loss: 2953.4568 - val_loss: 2684.0859\n",
      "Epoch 106/200\n",
      "960/960 [==============================] - 0s 24us/step - loss: 2799.3827 - val_loss: 2539.5944\n",
      "Epoch 107/200\n",
      "960/960 [==============================] - 0s 24us/step - loss: 2652.1277 - val_loss: 2402.4706\n",
      "Epoch 108/200\n",
      "960/960 [==============================] - 0s 38us/step - loss: 2513.2634 - val_loss: 2271.2685\n",
      "Epoch 109/200\n",
      "960/960 [==============================] - 0s 27us/step - loss: 2379.3791 - val_loss: 2147.0392\n",
      "Epoch 110/200\n",
      "960/960 [==============================] - 0s 24us/step - loss: 2252.9260 - val_loss: 2028.9827\n",
      "Epoch 111/200\n",
      "960/960 [==============================] - 0s 36us/step - loss: 2132.8623 - val_loss: 1916.6451\n",
      "Epoch 112/200\n",
      "960/960 [==============================] - 0s 31us/step - loss: 2018.0353 - val_loss: 1810.6378\n",
      "Epoch 113/200\n",
      "960/960 [==============================] - 0s 28us/step - loss: 1909.5708 - val_loss: 1710.4883\n",
      "Epoch 114/200\n",
      "960/960 [==============================] - 0s 34us/step - loss: 1807.3363 - val_loss: 1615.5058\n",
      "Epoch 115/200\n",
      "960/960 [==============================] - 0s 39us/step - loss: 1709.5856 - val_loss: 1526.0062\n",
      "Epoch 116/200\n",
      "960/960 [==============================] - 0s 44us/step - loss: 1617.8862 - val_loss: 1441.5666\n",
      "Epoch 117/200\n",
      "960/960 [==============================] - 0s 40us/step - loss: 1531.0488 - val_loss: 1361.7847\n",
      "Epoch 118/200\n",
      "960/960 [==============================] - 0s 30us/step - loss: 1448.7968 - val_loss: 1286.9829\n",
      "Epoch 119/200\n",
      "960/960 [==============================] - 0s 27us/step - loss: 1371.9709 - val_loss: 1216.0819\n",
      "Epoch 120/200\n",
      "960/960 [==============================] - 0s 37us/step - loss: 1298.8372 - val_loss: 1150.6922\n",
      "Epoch 121/200\n",
      "960/960 [==============================] - 0s 29us/step - loss: 1230.4838 - val_loss: 1088.7827\n",
      "Epoch 122/200\n",
      "960/960 [==============================] - 0s 27us/step - loss: 1166.5418 - val_loss: 1030.8429\n",
      "Epoch 123/200\n",
      "960/960 [==============================] - 0s 37us/step - loss: 1106.0472 - val_loss: 976.0193\n",
      "Epoch 124/200\n",
      "960/960 [==============================] - 0s 25us/step - loss: 1049.3597 - val_loss: 925.4387\n",
      "Epoch 125/200\n",
      "960/960 [==============================] - 0s 27us/step - loss: 996.5863 - val_loss: 877.8948\n",
      "Epoch 126/200\n",
      "960/960 [==============================] - 0s 38us/step - loss: 946.6030 - val_loss: 834.1344\n",
      "Epoch 127/200\n",
      "960/960 [==============================] - 0s 27us/step - loss: 900.3319 - val_loss: 793.0191\n",
      "Epoch 128/200\n",
      "960/960 [==============================] - 0s 26us/step - loss: 857.4708 - val_loss: 754.5901\n",
      "Epoch 129/200\n",
      "960/960 [==============================] - 0s 28us/step - loss: 816.5429 - val_loss: 719.3619\n",
      "Epoch 130/200\n",
      "960/960 [==============================] - 0s 33us/step - loss: 778.6324 - val_loss: 686.7790\n",
      "Epoch 131/200\n",
      "960/960 [==============================] - 0s 25us/step - loss: 744.2001 - val_loss: 655.9312\n",
      "Epoch 132/200\n",
      "960/960 [==============================] - 0s 27us/step - loss: 711.0995 - val_loss: 627.8878\n",
      "Epoch 133/200\n",
      "960/960 [==============================] - 0s 33us/step - loss: 680.6955 - val_loss: 601.8651\n",
      "Epoch 134/200\n",
      "960/960 [==============================] - 0s 21us/step - loss: 653.0413 - val_loss: 577.4861\n",
      "Epoch 135/200\n",
      "960/960 [==============================] - 0s 26us/step - loss: 626.3975 - val_loss: 555.5690\n",
      "Epoch 136/200\n",
      "960/960 [==============================] - 0s 28us/step - loss: 602.0353 - val_loss: 535.5139\n",
      "Epoch 137/200\n",
      "960/960 [==============================] - 0s 39us/step - loss: 579.9234 - val_loss: 516.4907\n",
      "Epoch 138/200\n",
      "960/960 [==============================] - 0s 37us/step - loss: 559.0950 - val_loss: 499.1671\n",
      "Epoch 139/200\n",
      "960/960 [==============================] - 0s 49us/step - loss: 539.6807 - val_loss: 483.5355\n",
      "Epoch 140/200\n",
      "960/960 [==============================] - 0s 44us/step - loss: 522.1067 - val_loss: 468.9070\n",
      "Epoch 141/200\n",
      "960/960 [==============================] - 0s 34us/step - loss: 505.5917 - val_loss: 455.5797\n",
      "Epoch 142/200\n",
      "960/960 [==============================] - 0s 41us/step - loss: 490.5623 - val_loss: 443.2538\n",
      "Epoch 143/200\n",
      "960/960 [==============================] - 0s 34us/step - loss: 476.4349 - val_loss: 432.2805\n",
      "Epoch 144/200\n",
      "960/960 [==============================] - 0s 33us/step - loss: 463.6046 - val_loss: 422.2335\n",
      "Epoch 145/200\n",
      "960/960 [==============================] - 0s 58us/step - loss: 451.6823 - val_loss: 413.0758\n",
      "Epoch 146/200\n",
      "960/960 [==============================] - 0s 36us/step - loss: 441.0297 - val_loss: 404.7137\n",
      "Epoch 147/200\n",
      "960/960 [==============================] - 0s 38us/step - loss: 430.8858 - val_loss: 397.1171\n",
      "Epoch 148/200\n",
      "960/960 [==============================] - 0s 35us/step - loss: 421.5046 - val_loss: 390.2799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149/200\n",
      "960/960 [==============================] - 0s 33us/step - loss: 413.2732 - val_loss: 384.0385\n",
      "Epoch 150/200\n",
      "960/960 [==============================] - 0s 51us/step - loss: 405.3238 - val_loss: 378.6240\n",
      "Epoch 151/200\n",
      "960/960 [==============================] - 0s 35us/step - loss: 398.1281 - val_loss: 373.5586\n",
      "Epoch 152/200\n",
      "960/960 [==============================] - 0s 49us/step - loss: 391.5359 - val_loss: 369.2505\n",
      "Epoch 153/200\n",
      "960/960 [==============================] - 0s 41us/step - loss: 385.6765 - val_loss: 364.9954\n",
      "Epoch 154/200\n",
      "960/960 [==============================] - 0s 50us/step - loss: 379.9188 - val_loss: 361.3913\n",
      "Epoch 155/200\n",
      "960/960 [==============================] - 0s 43us/step - loss: 374.8662 - val_loss: 358.2630\n",
      "Epoch 156/200\n",
      "960/960 [==============================] - 0s 33us/step - loss: 370.4182 - val_loss: 355.1995\n",
      "Epoch 157/200\n",
      "960/960 [==============================] - 0s 41us/step - loss: 366.1617 - val_loss: 352.4779\n",
      "Epoch 158/200\n",
      "960/960 [==============================] - 0s 34us/step - loss: 362.0841 - val_loss: 350.2072\n",
      "Epoch 159/200\n",
      "960/960 [==============================] - 0s 41us/step - loss: 358.4217 - val_loss: 348.2598\n",
      "Epoch 160/200\n",
      "960/960 [==============================] - 0s 37us/step - loss: 355.2730 - val_loss: 346.2930\n",
      "Epoch 161/200\n",
      "960/960 [==============================] - 0s 34us/step - loss: 352.1532 - val_loss: 344.7562\n",
      "Epoch 162/200\n",
      "960/960 [==============================] - 0s 50us/step - loss: 349.4188 - val_loss: 343.4338\n",
      "Epoch 163/200\n",
      "960/960 [==============================] - 0s 36us/step - loss: 346.8343 - val_loss: 342.1316\n",
      "Epoch 164/200\n",
      "960/960 [==============================] - 0s 30us/step - loss: 344.5357 - val_loss: 340.9191\n",
      "Epoch 165/200\n",
      "960/960 [==============================] - 0s 38us/step - loss: 342.3514 - val_loss: 340.0352\n",
      "Epoch 166/200\n",
      "960/960 [==============================] - 0s 25us/step - loss: 340.3684 - val_loss: 339.3260\n",
      "Epoch 167/200\n",
      "960/960 [==============================] - 0s 34us/step - loss: 338.6339 - val_loss: 338.5361\n",
      "Epoch 168/200\n",
      "960/960 [==============================] - 0s 54us/step - loss: 336.9244 - val_loss: 337.9555\n",
      "Epoch 169/200\n",
      "960/960 [==============================] - 0s 37us/step - loss: 335.3990 - val_loss: 337.2981\n",
      "Epoch 170/200\n",
      "960/960 [==============================] - 0s 49us/step - loss: 333.9925 - val_loss: 336.8735\n",
      "Epoch 171/200\n",
      "960/960 [==============================] - 0s 37us/step - loss: 332.7139 - val_loss: 336.4392\n",
      "Epoch 172/200\n",
      "960/960 [==============================] - 0s 47us/step - loss: 331.5574 - val_loss: 336.1543\n",
      "Epoch 173/200\n",
      "960/960 [==============================] - 0s 36us/step - loss: 330.3424 - val_loss: 336.1744\n",
      "Epoch 174/200\n",
      "960/960 [==============================] - 0s 38us/step - loss: 329.3898 - val_loss: 336.0516\n",
      "Epoch 175/200\n",
      "960/960 [==============================] - 0s 41us/step - loss: 328.4360 - val_loss: 335.9287\n",
      "Epoch 176/200\n",
      "960/960 [==============================] - 0s 30us/step - loss: 327.5600 - val_loss: 335.8135\n",
      "Epoch 177/200\n",
      "960/960 [==============================] - 0s 34us/step - loss: 326.6967 - val_loss: 335.7019\n",
      "Epoch 178/200\n",
      "960/960 [==============================] - 0s 46us/step - loss: 326.0521 - val_loss: 335.7748\n",
      "Epoch 179/200\n",
      "960/960 [==============================] - 0s 26us/step - loss: 325.4231 - val_loss: 335.8721\n",
      "Epoch 180/200\n",
      "960/960 [==============================] - 0s 29us/step - loss: 324.6736 - val_loss: 335.9763\n",
      "Epoch 181/200\n",
      "960/960 [==============================] - 0s 34us/step - loss: 324.1332 - val_loss: 335.7046\n",
      "Epoch 182/200\n",
      "960/960 [==============================] - 0s 30us/step - loss: 323.6095 - val_loss: 335.9209\n",
      "Epoch 183/200\n",
      "960/960 [==============================] - 0s 30us/step - loss: 323.0831 - val_loss: 336.1386\n",
      "Epoch 184/200\n",
      "960/960 [==============================] - 0s 39us/step - loss: 322.5790 - val_loss: 336.0995\n",
      "Epoch 185/200\n",
      "960/960 [==============================] - 0s 29us/step - loss: 322.2401 - val_loss: 336.2279\n",
      "Epoch 186/200\n",
      "960/960 [==============================] - 0s 33us/step - loss: 321.7742 - val_loss: 336.3576\n",
      "Epoch 187/200\n",
      "960/960 [==============================] - 0s 36us/step - loss: 321.3931 - val_loss: 336.4937\n",
      "Epoch 188/200\n",
      "960/960 [==============================] - 0s 30us/step - loss: 321.0737 - val_loss: 336.7445\n",
      "Epoch 189/200\n",
      "960/960 [==============================] - 0s 32us/step - loss: 320.7507 - val_loss: 336.9863\n",
      "Epoch 190/200\n",
      "960/960 [==============================] - 0s 40us/step - loss: 320.4624 - val_loss: 337.0077\n",
      "Epoch 191/200\n",
      "960/960 [==============================] - 0s 30us/step - loss: 320.1732 - val_loss: 337.1934\n",
      "Epoch 192/200\n",
      "960/960 [==============================] - 0s 30us/step - loss: 319.9533 - val_loss: 337.2905\n",
      "Epoch 193/200\n",
      "960/960 [==============================] - 0s 41us/step - loss: 319.6274 - val_loss: 337.4116\n",
      "Epoch 194/200\n",
      "960/960 [==============================] - 0s 38us/step - loss: 319.4614 - val_loss: 337.8404\n",
      "Epoch 195/200\n",
      "960/960 [==============================] - 0s 31us/step - loss: 319.2870 - val_loss: 337.7616\n",
      "Epoch 196/200\n",
      "960/960 [==============================] - 0s 40us/step - loss: 319.0809 - val_loss: 338.0273\n",
      "Epoch 197/200\n",
      "960/960 [==============================] - 0s 26us/step - loss: 318.9032 - val_loss: 338.2663\n",
      "Epoch 198/200\n",
      "960/960 [==============================] - 0s 28us/step - loss: 318.6958 - val_loss: 338.3979\n",
      "Epoch 199/200\n",
      "960/960 [==============================] - 0s 39us/step - loss: 318.6424 - val_loss: 338.5879\n",
      "Epoch 200/200\n",
      "960/960 [==============================] - 0s 32us/step - loss: 318.4164 - val_loss: 338.7610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11f7010f0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit([trn.VISITOR_TEAM, trn.HOME_TEAM], trn.HOME_POINTS + trn.VISITOR_POINTS, batch_size=64, epochs=200, \n",
    "          validation_data=([val.VISITOR_TEAM, val.HOME_TEAM], val.HOME_POINTS + val.VISITOR_POINTS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATING A SIMPLE NEURAL NETWORK MODEL USING EMMBEDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  \n",
      "/usr/local/lib/python3.6/site-packages/keras/legacy/layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n"
     ]
    }
   ],
   "source": [
    "# Creating the neural network\n",
    "x = merge([u, m], mode='concat')\n",
    "x = Flatten()(x)\n",
    "#x = Dropout(0.0)(x)\n",
    "#x = Dense(50, activation='relu')(x)\n",
    "#x = Dropout(0.0)(x)\n",
    "x = Dense(1)(x)\n",
    "neuralModel = Model([visitor_in, home_in], x)\n",
    "neuralModel.compile(Adam(0.001), loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "home_in (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "visitor_in (InputLayer)         (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 1, 50)        1450        home_in[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 1, 50)        1450        visitor_in[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_3 (Merge)                 (None, 1, 100)       0           embedding_5[0][0]                \n",
      "                                                                 embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 100)          0           merge_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            101         flatten_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,001\n",
      "Trainable params: 3,001\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "neuralModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 960 samples, validate on 241 samples\n",
      "Epoch 1/300\n",
      "960/960 [==============================] - 0s 34us/step - loss: 438.2673 - val_loss: 370.8574\n",
      "Epoch 2/300\n",
      "960/960 [==============================] - 0s 36us/step - loss: 427.2243 - val_loss: 363.4533\n",
      "Epoch 3/300\n",
      "960/960 [==============================] - 0s 79us/step - loss: 417.4089 - val_loss: 357.3821\n",
      "Epoch 4/300\n",
      "960/960 [==============================] - 0s 38us/step - loss: 409.0067 - val_loss: 352.1875\n",
      "Epoch 5/300\n",
      "960/960 [==============================] - 0s 51us/step - loss: 401.5692 - val_loss: 348.0520\n",
      "Epoch 6/300\n",
      "960/960 [==============================] - 0s 33us/step - loss: 395.3753 - val_loss: 344.4025\n",
      "Epoch 7/300\n",
      "960/960 [==============================] - 0s 33us/step - loss: 389.7479 - val_loss: 341.5195\n",
      "Epoch 8/300\n",
      "960/960 [==============================] - 0s 52us/step - loss: 384.7974 - val_loss: 339.1883\n",
      "Epoch 9/300\n",
      "960/960 [==============================] - 0s 35us/step - loss: 380.5352 - val_loss: 337.2635\n",
      "Epoch 10/300\n",
      "960/960 [==============================] - 0s 50us/step - loss: 376.9043 - val_loss: 335.6488\n",
      "Epoch 11/300\n",
      "960/960 [==============================] - 0s 32us/step - loss: 373.4464 - val_loss: 334.4450\n",
      "Epoch 12/300\n",
      "960/960 [==============================] - 0s 34us/step - loss: 370.6430 - val_loss: 333.4320\n",
      "Epoch 13/300\n",
      "960/960 [==============================] - 0s 53us/step - loss: 368.0836 - val_loss: 332.5686\n",
      "Epoch 14/300\n",
      "960/960 [==============================] - 0s 35us/step - loss: 365.6305 - val_loss: 332.0272\n",
      "Epoch 15/300\n",
      "960/960 [==============================] - 0s 66us/step - loss: 363.5572 - val_loss: 331.5581\n",
      "Epoch 16/300\n",
      "960/960 [==============================] - 0s 37us/step - loss: 361.7868 - val_loss: 331.1129\n",
      "Epoch 17/300\n",
      "960/960 [==============================] - 0s 53us/step - loss: 359.8840 - val_loss: 330.8627\n",
      "Epoch 18/300\n",
      "960/960 [==============================] - 0s 40us/step - loss: 358.3195 - val_loss: 330.6574\n",
      "Epoch 19/300\n",
      "960/960 [==============================] - 0s 47us/step - loss: 356.9508 - val_loss: 330.4846\n",
      "Epoch 20/300\n",
      "960/960 [==============================] - 0s 38us/step - loss: 355.6036 - val_loss: 330.3825\n",
      "Epoch 21/300\n",
      "960/960 [==============================] - 0s 42us/step - loss: 354.3142 - val_loss: 330.3884\n",
      "Epoch 22/300\n",
      "960/960 [==============================] - 0s 45us/step - loss: 353.1274 - val_loss: 330.3002\n",
      "Epoch 23/300\n",
      "960/960 [==============================] - 0s 42us/step - loss: 352.0033 - val_loss: 330.2782\n",
      "Epoch 24/300\n",
      "960/960 [==============================] - 0s 53us/step - loss: 350.9301 - val_loss: 330.2358\n",
      "Epoch 25/300\n",
      "960/960 [==============================] - 0s 50us/step - loss: 349.9749 - val_loss: 330.2025\n",
      "Epoch 26/300\n",
      "960/960 [==============================] - 0s 51us/step - loss: 349.0508 - val_loss: 330.2941\n",
      "Epoch 27/300\n",
      "960/960 [==============================] - 0s 39us/step - loss: 348.0199 - val_loss: 330.2036\n",
      "Epoch 28/300\n",
      "960/960 [==============================] - 0s 58us/step - loss: 347.1567 - val_loss: 330.2111\n",
      "Epoch 29/300\n",
      "960/960 [==============================] - 0s 37us/step - loss: 346.3545 - val_loss: 330.2990\n",
      "Epoch 30/300\n",
      "960/960 [==============================] - 0s 60us/step - loss: 345.4681 - val_loss: 330.2306\n",
      "Epoch 31/300\n",
      "960/960 [==============================] - 0s 33us/step - loss: 344.7067 - val_loss: 330.2975\n",
      "Epoch 32/300\n",
      "960/960 [==============================] - 0s 42us/step - loss: 343.9295 - val_loss: 330.3813\n",
      "Epoch 33/300\n",
      "960/960 [==============================] - 0s 50us/step - loss: 343.1950 - val_loss: 330.3681\n",
      "Epoch 34/300\n",
      "960/960 [==============================] - 0s 38us/step - loss: 342.3789 - val_loss: 330.3847\n",
      "Epoch 35/300\n",
      "960/960 [==============================] - 0s 47us/step - loss: 341.6709 - val_loss: 330.3307\n",
      "Epoch 36/300\n",
      "960/960 [==============================] - 0s 33us/step - loss: 341.0046 - val_loss: 330.3425\n",
      "Epoch 37/300\n",
      "960/960 [==============================] - 0s 54us/step - loss: 340.2876 - val_loss: 330.2902\n",
      "Epoch 38/300\n",
      "960/960 [==============================] - 0s 31us/step - loss: 339.6347 - val_loss: 330.4760\n",
      "Epoch 39/300\n",
      "960/960 [==============================] - 0s 39us/step - loss: 338.9808 - val_loss: 330.4359\n",
      "Epoch 40/300\n",
      "960/960 [==============================] - 0s 49us/step - loss: 338.3680 - val_loss: 330.5724\n",
      "Epoch 41/300\n",
      "960/960 [==============================] - 0s 38us/step - loss: 337.7308 - val_loss: 330.5692\n",
      "Epoch 42/300\n",
      "960/960 [==============================] - 0s 47us/step - loss: 337.1244 - val_loss: 330.6814\n",
      "Epoch 43/300\n",
      "960/960 [==============================] - 0s 39us/step - loss: 336.4899 - val_loss: 330.7242\n",
      "Epoch 44/300\n",
      "960/960 [==============================] - 0s 41us/step - loss: 335.9704 - val_loss: 330.7131\n",
      "Epoch 45/300\n",
      "960/960 [==============================] - 0s 48us/step - loss: 335.3903 - val_loss: 330.7393\n",
      "Epoch 46/300\n",
      "960/960 [==============================] - 0s 34us/step - loss: 334.9332 - val_loss: 330.9665\n",
      "Epoch 47/300\n",
      "960/960 [==============================] - 0s 49us/step - loss: 334.3110 - val_loss: 330.9048\n",
      "Epoch 48/300\n",
      "960/960 [==============================] - 0s 38us/step - loss: 333.7769 - val_loss: 330.8931\n",
      "Epoch 49/300\n",
      "960/960 [==============================] - 0s 51us/step - loss: 333.2952 - val_loss: 330.9696\n",
      "Epoch 50/300\n",
      "960/960 [==============================] - 0s 34us/step - loss: 332.8194 - val_loss: 331.0154\n",
      "Epoch 51/300\n",
      "960/960 [==============================] - 0s 39us/step - loss: 332.3620 - val_loss: 331.1396\n",
      "Epoch 52/300\n",
      "960/960 [==============================] - 0s 38us/step - loss: 331.8559 - val_loss: 331.1645\n",
      "Epoch 53/300\n",
      "960/960 [==============================] - 0s 30us/step - loss: 331.3791 - val_loss: 331.2882\n",
      "Epoch 54/300\n",
      "960/960 [==============================] - 0s 38us/step - loss: 330.9625 - val_loss: 331.3819\n",
      "Epoch 55/300\n",
      "960/960 [==============================] - 0s 37us/step - loss: 330.4723 - val_loss: 331.5412\n",
      "Epoch 56/300\n",
      "960/960 [==============================] - 0s 33us/step - loss: 330.1244 - val_loss: 331.6780\n",
      "Epoch 57/300\n",
      "960/960 [==============================] - 0s 38us/step - loss: 329.6874 - val_loss: 331.7156\n",
      "Epoch 58/300\n",
      "960/960 [==============================] - 0s 50us/step - loss: 329.3395 - val_loss: 331.9334\n",
      "Epoch 59/300\n",
      "960/960 [==============================] - 0s 33us/step - loss: 328.8691 - val_loss: 332.0243\n",
      "Epoch 60/300\n",
      "960/960 [==============================] - 0s 37us/step - loss: 328.5594 - val_loss: 332.1489\n",
      "Epoch 61/300\n",
      "960/960 [==============================] - 0s 30us/step - loss: 328.1329 - val_loss: 332.1577\n",
      "Epoch 62/300\n",
      "960/960 [==============================] - 0s 32us/step - loss: 327.7832 - val_loss: 332.3485\n",
      "Epoch 63/300\n",
      "960/960 [==============================] - 0s 47us/step - loss: 327.4317 - val_loss: 332.3086\n",
      "Epoch 64/300\n",
      "960/960 [==============================] - 0s 27us/step - loss: 327.1006 - val_loss: 332.4630\n",
      "Epoch 65/300\n",
      "960/960 [==============================] - 0s 28us/step - loss: 326.7679 - val_loss: 332.6620\n",
      "Epoch 66/300\n",
      "960/960 [==============================] - 0s 35us/step - loss: 326.4832 - val_loss: 332.7463\n",
      "Epoch 67/300\n",
      "960/960 [==============================] - 0s 25us/step - loss: 326.1479 - val_loss: 332.9335\n",
      "Epoch 68/300\n",
      "960/960 [==============================] - 0s 28us/step - loss: 325.8314 - val_loss: 333.1515\n",
      "Epoch 69/300\n",
      "960/960 [==============================] - 0s 28us/step - loss: 325.6075 - val_loss: 333.3468\n",
      "Epoch 70/300\n",
      "960/960 [==============================] - 0s 35us/step - loss: 325.2588 - val_loss: 333.4671\n",
      "Epoch 71/300\n",
      "960/960 [==============================] - 0s 29us/step - loss: 325.0199 - val_loss: 333.5859\n",
      "Epoch 72/300\n",
      "960/960 [==============================] - 0s 27us/step - loss: 324.7349 - val_loss: 333.7535\n",
      "Epoch 73/300\n",
      "960/960 [==============================] - 0s 36us/step - loss: 324.5400 - val_loss: 333.9528\n",
      "Epoch 74/300\n",
      "960/960 [==============================] - 0s 24us/step - loss: 324.2235 - val_loss: 334.0361\n",
      "Epoch 75/300\n",
      "960/960 [==============================] - 0s 30us/step - loss: 323.9946 - val_loss: 334.1940\n",
      "Epoch 76/300\n",
      "960/960 [==============================] - 0s 35us/step - loss: 323.7795 - val_loss: 334.3670\n",
      "Epoch 77/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "960/960 [==============================] - 0s 26us/step - loss: 323.5759 - val_loss: 334.5582\n",
      "Epoch 78/300\n",
      "960/960 [==============================] - 0s 26us/step - loss: 323.3268 - val_loss: 334.7985\n",
      "Epoch 79/300\n",
      "960/960 [==============================] - 0s 27us/step - loss: 323.1291 - val_loss: 334.7764\n",
      "Epoch 80/300\n",
      "960/960 [==============================] - 0s 42us/step - loss: 322.9248 - val_loss: 334.9820\n",
      "Epoch 81/300\n",
      "960/960 [==============================] - 0s 31us/step - loss: 322.7458 - val_loss: 335.1448\n",
      "Epoch 82/300\n",
      "960/960 [==============================] - 0s 30us/step - loss: 322.5268 - val_loss: 335.2619\n",
      "Epoch 83/300\n",
      "960/960 [==============================] - 0s 33us/step - loss: 322.3001 - val_loss: 335.5580\n",
      "Epoch 84/300\n",
      "960/960 [==============================] - 0s 23us/step - loss: 322.2052 - val_loss: 335.4827\n",
      "Epoch 85/300\n",
      "960/960 [==============================] - 0s 27us/step - loss: 321.9899 - val_loss: 335.8127\n",
      "Epoch 86/300\n",
      "960/960 [==============================] - 0s 42us/step - loss: 321.8148 - val_loss: 336.0540\n",
      "Epoch 87/300\n",
      "960/960 [==============================] - 0s 45us/step - loss: 321.6908 - val_loss: 336.3745\n",
      "Epoch 88/300\n",
      "960/960 [==============================] - 0s 55us/step - loss: 321.5133 - val_loss: 336.2980\n",
      "Epoch 89/300\n",
      "960/960 [==============================] - 0s 44us/step - loss: 321.3450 - val_loss: 336.5654\n",
      "Epoch 90/300\n",
      "960/960 [==============================] - 0s 41us/step - loss: 321.2253 - val_loss: 336.7109\n",
      "Epoch 91/300\n",
      "960/960 [==============================] - 0s 43us/step - loss: 321.0451 - val_loss: 336.8128\n",
      "Epoch 92/300\n",
      "960/960 [==============================] - 0s 38us/step - loss: 320.9675 - val_loss: 336.7874\n",
      "Epoch 93/300\n",
      "960/960 [==============================] - 0s 47us/step - loss: 320.8364 - val_loss: 337.0979\n",
      "Epoch 94/300\n",
      "960/960 [==============================] - 0s 37us/step - loss: 320.7095 - val_loss: 337.2006\n",
      "Epoch 95/300\n",
      "960/960 [==============================] - 0s 50us/step - loss: 320.5863 - val_loss: 337.6079\n",
      "Epoch 96/300\n",
      "960/960 [==============================] - 0s 47us/step - loss: 320.4103 - val_loss: 337.7407\n",
      "Epoch 97/300\n",
      "960/960 [==============================] - 0s 55us/step - loss: 320.3130 - val_loss: 337.7615\n",
      "Epoch 98/300\n",
      "960/960 [==============================] - 0s 40us/step - loss: 320.2182 - val_loss: 337.9308\n",
      "Epoch 99/300\n",
      "960/960 [==============================] - 0s 55us/step - loss: 320.1231 - val_loss: 338.0225\n",
      "Epoch 100/300\n",
      "960/960 [==============================] - 0s 41us/step - loss: 320.0030 - val_loss: 338.3451\n",
      "Epoch 101/300\n",
      "960/960 [==============================] - 0s 39us/step - loss: 319.9109 - val_loss: 338.3179\n",
      "Epoch 102/300\n",
      "960/960 [==============================] - 0s 45us/step - loss: 319.8642 - val_loss: 338.4445\n",
      "Epoch 103/300\n",
      "960/960 [==============================] - 0s 31us/step - loss: 319.7887 - val_loss: 338.8209\n",
      "Epoch 104/300\n",
      "960/960 [==============================] - 0s 50us/step - loss: 319.6561 - val_loss: 338.9033\n",
      "Epoch 105/300\n",
      "960/960 [==============================] - 0s 44us/step - loss: 319.5862 - val_loss: 339.1318\n",
      "Epoch 106/300\n",
      "960/960 [==============================] - 0s 48us/step - loss: 319.4744 - val_loss: 339.2647\n",
      "Epoch 107/300\n",
      "960/960 [==============================] - 0s 34us/step - loss: 319.4118 - val_loss: 339.3546\n",
      "Epoch 108/300\n",
      "960/960 [==============================] - 0s 30us/step - loss: 319.3964 - val_loss: 339.5875\n",
      "Epoch 109/300\n",
      "960/960 [==============================] - 0s 43us/step - loss: 319.2685 - val_loss: 339.6870\n",
      "Epoch 110/300\n",
      "960/960 [==============================] - 0s 38us/step - loss: 319.2408 - val_loss: 339.6929\n",
      "Epoch 111/300\n",
      "960/960 [==============================] - 0s 43us/step - loss: 319.1157 - val_loss: 339.8719\n",
      "Epoch 112/300\n",
      "960/960 [==============================] - 0s 42us/step - loss: 319.0650 - val_loss: 339.9655\n",
      "Epoch 113/300\n",
      "960/960 [==============================] - 0s 42us/step - loss: 319.1314 - val_loss: 340.3641\n",
      "Epoch 114/300\n",
      "960/960 [==============================] - 0s 36us/step - loss: 318.9435 - val_loss: 340.4947\n",
      "Epoch 115/300\n",
      "960/960 [==============================] - 0s 33us/step - loss: 318.9016 - val_loss: 340.5307\n",
      "Epoch 116/300\n",
      "960/960 [==============================] - 0s 52us/step - loss: 318.8440 - val_loss: 340.5055\n",
      "Epoch 117/300\n",
      "960/960 [==============================] - 0s 38us/step - loss: 318.8247 - val_loss: 340.7313\n",
      "Epoch 118/300\n",
      "960/960 [==============================] - 0s 57us/step - loss: 318.7574 - val_loss: 340.8795\n",
      "Epoch 119/300\n",
      "960/960 [==============================] - 0s 42us/step - loss: 318.6875 - val_loss: 341.0640\n",
      "Epoch 120/300\n",
      "960/960 [==============================] - 0s 56us/step - loss: 318.6781 - val_loss: 341.1848\n",
      "Epoch 121/300\n",
      "960/960 [==============================] - 0s 37us/step - loss: 318.6396 - val_loss: 341.3338\n",
      "Epoch 122/300\n",
      "960/960 [==============================] - 0s 29us/step - loss: 318.6327 - val_loss: 341.2625\n",
      "Epoch 123/300\n",
      "960/960 [==============================] - 0s 53us/step - loss: 318.5551 - val_loss: 341.2629\n",
      "Epoch 124/300\n",
      "960/960 [==============================] - 0s 39us/step - loss: 318.5581 - val_loss: 341.3980\n",
      "Epoch 125/300\n",
      "960/960 [==============================] - 0s 42us/step - loss: 318.5185 - val_loss: 341.6543\n",
      "Epoch 126/300\n",
      "960/960 [==============================] - 0s 36us/step - loss: 318.4687 - val_loss: 341.5664\n",
      "Epoch 127/300\n",
      "960/960 [==============================] - 0s 40us/step - loss: 318.4213 - val_loss: 341.9021\n",
      "Epoch 128/300\n",
      "960/960 [==============================] - 0s 39us/step - loss: 318.4100 - val_loss: 341.8992\n",
      "Epoch 129/300\n",
      "960/960 [==============================] - 0s 38us/step - loss: 318.3905 - val_loss: 342.1466\n",
      "Epoch 130/300\n",
      "960/960 [==============================] - 0s 44us/step - loss: 318.3168 - val_loss: 342.3934\n",
      "Epoch 131/300\n",
      "960/960 [==============================] - 0s 39us/step - loss: 318.2999 - val_loss: 342.5907\n",
      "Epoch 132/300\n",
      "960/960 [==============================] - 0s 46us/step - loss: 318.2658 - val_loss: 342.5963\n",
      "Epoch 133/300\n",
      "960/960 [==============================] - 0s 41us/step - loss: 318.4835 - val_loss: 342.2980\n",
      "Epoch 134/300\n",
      "960/960 [==============================] - 0s 45us/step - loss: 318.2526 - val_loss: 342.6727\n",
      "Epoch 135/300\n",
      "960/960 [==============================] - 0s 35us/step - loss: 318.1925 - val_loss: 342.7732\n",
      "Epoch 136/300\n",
      "960/960 [==============================] - 0s 39us/step - loss: 318.1914 - val_loss: 342.8422\n",
      "Epoch 137/300\n",
      "960/960 [==============================] - 0s 43us/step - loss: 318.1825 - val_loss: 342.9999\n",
      "Epoch 138/300\n",
      "960/960 [==============================] - 0s 35us/step - loss: 318.2217 - val_loss: 342.9468\n",
      "Epoch 139/300\n",
      "960/960 [==============================] - 0s 35us/step - loss: 318.1508 - val_loss: 343.3471\n",
      "Epoch 140/300\n",
      "960/960 [==============================] - 0s 37us/step - loss: 318.1400 - val_loss: 343.1699\n",
      "Epoch 141/300\n",
      "960/960 [==============================] - 0s 35us/step - loss: 318.1216 - val_loss: 343.3477\n",
      "Epoch 142/300\n",
      "960/960 [==============================] - 0s 44us/step - loss: 318.1000 - val_loss: 343.5893\n",
      "Epoch 143/300\n",
      "960/960 [==============================] - 0s 49us/step - loss: 318.0944 - val_loss: 343.4036\n",
      "Epoch 144/300\n",
      "960/960 [==============================] - 0s 34us/step - loss: 318.0944 - val_loss: 343.6212\n",
      "Epoch 145/300\n",
      "960/960 [==============================] - 0s 37us/step - loss: 318.1063 - val_loss: 343.5858\n",
      "Epoch 146/300\n",
      "960/960 [==============================] - 0s 32us/step - loss: 318.0157 - val_loss: 343.6642\n",
      "Epoch 147/300\n",
      "960/960 [==============================] - 0s 29us/step - loss: 318.0733 - val_loss: 343.9350\n",
      "Epoch 148/300\n",
      "960/960 [==============================] - 0s 37us/step - loss: 318.0117 - val_loss: 343.8953\n",
      "Epoch 149/300\n",
      "960/960 [==============================] - 0s 33us/step - loss: 318.1237 - val_loss: 343.7168\n",
      "Epoch 150/300\n",
      "960/960 [==============================] - 0s 32us/step - loss: 318.0404 - val_loss: 344.4574\n",
      "Epoch 151/300\n",
      "960/960 [==============================] - 0s 46us/step - loss: 318.0571 - val_loss: 344.1486\n",
      "Epoch 152/300\n",
      "960/960 [==============================] - 0s 34us/step - loss: 317.9781 - val_loss: 344.3047\n",
      "Epoch 153/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "960/960 [==============================] - 0s 42us/step - loss: 318.0071 - val_loss: 344.4448\n",
      "Epoch 154/300\n",
      "960/960 [==============================] - 0s 34us/step - loss: 317.9622 - val_loss: 344.4334\n",
      "Epoch 155/300\n",
      "960/960 [==============================] - 0s 31us/step - loss: 317.9444 - val_loss: 344.4290\n",
      "Epoch 156/300\n",
      "960/960 [==============================] - 0s 52us/step - loss: 317.9025 - val_loss: 344.3292\n",
      "Epoch 157/300\n",
      "960/960 [==============================] - 0s 34us/step - loss: 317.9522 - val_loss: 344.3228\n",
      "Epoch 158/300\n",
      "960/960 [==============================] - 0s 57us/step - loss: 317.9210 - val_loss: 344.5314\n",
      "Epoch 159/300\n",
      "960/960 [==============================] - 0s 33us/step - loss: 317.9468 - val_loss: 344.4383\n",
      "Epoch 160/300\n",
      "960/960 [==============================] - 0s 59us/step - loss: 317.9257 - val_loss: 344.5323\n",
      "Epoch 161/300\n",
      "960/960 [==============================] - 0s 45us/step - loss: 317.9823 - val_loss: 344.5414\n",
      "Epoch 162/300\n",
      "960/960 [==============================] - 0s 62us/step - loss: 317.9381 - val_loss: 344.9485\n",
      "Epoch 163/300\n",
      "960/960 [==============================] - 0s 43us/step - loss: 317.9861 - val_loss: 344.8136\n",
      "Epoch 164/300\n",
      "960/960 [==============================] - 0s 63us/step - loss: 318.0072 - val_loss: 344.8910\n",
      "Epoch 165/300\n",
      "960/960 [==============================] - 0s 41us/step - loss: 317.9110 - val_loss: 345.0420\n",
      "Epoch 166/300\n",
      "960/960 [==============================] - 0s 48us/step - loss: 317.8978 - val_loss: 344.9833\n",
      "Epoch 167/300\n",
      "960/960 [==============================] - 0s 43us/step - loss: 317.8840 - val_loss: 345.1099\n",
      "Epoch 168/300\n",
      "960/960 [==============================] - 0s 35us/step - loss: 317.8864 - val_loss: 345.0780\n",
      "Epoch 169/300\n",
      "960/960 [==============================] - 0s 49us/step - loss: 317.9136 - val_loss: 344.9419\n",
      "Epoch 170/300\n",
      "960/960 [==============================] - 0s 35us/step - loss: 317.8513 - val_loss: 345.1277\n",
      "Epoch 171/300\n",
      "960/960 [==============================] - 0s 54us/step - loss: 317.8850 - val_loss: 345.1724\n",
      "Epoch 172/300\n",
      "960/960 [==============================] - 0s 32us/step - loss: 317.9394 - val_loss: 345.5322\n",
      "Epoch 173/300\n",
      "960/960 [==============================] - 0s 54us/step - loss: 317.8877 - val_loss: 345.3985\n",
      "Epoch 174/300\n",
      "960/960 [==============================] - 0s 41us/step - loss: 317.8698 - val_loss: 345.2393\n",
      "Epoch 175/300\n",
      "960/960 [==============================] - 0s 54us/step - loss: 317.8547 - val_loss: 345.1774\n",
      "Epoch 176/300\n",
      "960/960 [==============================] - 0s 46us/step - loss: 317.8324 - val_loss: 345.5355\n",
      "Epoch 177/300\n",
      "960/960 [==============================] - 0s 62us/step - loss: 317.8809 - val_loss: 345.2811\n",
      "Epoch 178/300\n",
      "960/960 [==============================] - 0s 46us/step - loss: 317.8260 - val_loss: 345.4359\n",
      "Epoch 179/300\n",
      "960/960 [==============================] - 0s 62us/step - loss: 317.8676 - val_loss: 345.6341\n",
      "Epoch 180/300\n",
      "960/960 [==============================] - 0s 46us/step - loss: 317.8767 - val_loss: 345.2900\n",
      "Epoch 181/300\n",
      "960/960 [==============================] - 0s 53us/step - loss: 317.8357 - val_loss: 345.4596\n",
      "Epoch 182/300\n",
      "960/960 [==============================] - 0s 44us/step - loss: 317.8346 - val_loss: 345.5374\n",
      "Epoch 183/300\n",
      "960/960 [==============================] - 0s 45us/step - loss: 317.8886 - val_loss: 345.6350\n",
      "Epoch 184/300\n",
      "960/960 [==============================] - 0s 51us/step - loss: 317.8534 - val_loss: 345.4995\n",
      "Epoch 185/300\n",
      "960/960 [==============================] - 0s 50us/step - loss: 317.8627 - val_loss: 345.7492\n",
      "Epoch 186/300\n",
      "960/960 [==============================] - 0s 43us/step - loss: 317.8249 - val_loss: 345.6879\n",
      "Epoch 187/300\n",
      "960/960 [==============================] - 0s 31us/step - loss: 317.8280 - val_loss: 345.7877\n",
      "Epoch 188/300\n",
      "960/960 [==============================] - 0s 40us/step - loss: 317.8598 - val_loss: 345.9625\n",
      "Epoch 189/300\n",
      "960/960 [==============================] - 0s 33us/step - loss: 317.8620 - val_loss: 345.7814\n",
      "Epoch 190/300\n",
      "960/960 [==============================] - 0s 51us/step - loss: 317.8273 - val_loss: 345.6643\n",
      "Epoch 191/300\n",
      "960/960 [==============================] - 0s 27us/step - loss: 317.8631 - val_loss: 345.8616\n",
      "Epoch 192/300\n",
      "960/960 [==============================] - 0s 35us/step - loss: 317.8595 - val_loss: 345.7589\n",
      "Epoch 193/300\n",
      "960/960 [==============================] - 0s 62us/step - loss: 317.8435 - val_loss: 345.7806\n",
      "Epoch 194/300\n",
      "960/960 [==============================] - 0s 41us/step - loss: 317.8702 - val_loss: 345.8922\n",
      "Epoch 195/300\n",
      "960/960 [==============================] - 0s 54us/step - loss: 317.8672 - val_loss: 345.9626\n",
      "Epoch 196/300\n",
      "960/960 [==============================] - 0s 50us/step - loss: 317.8689 - val_loss: 346.1141\n",
      "Epoch 197/300\n",
      "960/960 [==============================] - 0s 53us/step - loss: 317.8566 - val_loss: 345.8831\n",
      "Epoch 198/300\n",
      "960/960 [==============================] - 0s 32us/step - loss: 317.8499 - val_loss: 345.8348\n",
      "Epoch 199/300\n",
      "960/960 [==============================] - 0s 45us/step - loss: 317.8914 - val_loss: 346.3289\n",
      "Epoch 200/300\n",
      "960/960 [==============================] - 0s 31us/step - loss: 317.8535 - val_loss: 345.9285\n",
      "Epoch 201/300\n",
      "960/960 [==============================] - 0s 30us/step - loss: 317.8821 - val_loss: 345.6466\n",
      "Epoch 202/300\n",
      "960/960 [==============================] - 0s 38us/step - loss: 317.8308 - val_loss: 346.0602\n",
      "Epoch 203/300\n",
      "960/960 [==============================] - 0s 28us/step - loss: 317.8468 - val_loss: 346.3504\n",
      "Epoch 204/300\n",
      "960/960 [==============================] - 0s 27us/step - loss: 317.9067 - val_loss: 346.1858\n",
      "Epoch 205/300\n",
      "960/960 [==============================] - 0s 42us/step - loss: 317.9451 - val_loss: 345.8387\n",
      "Epoch 206/300\n",
      "960/960 [==============================] - 0s 39us/step - loss: 317.7961 - val_loss: 345.9766\n",
      "Epoch 207/300\n",
      "960/960 [==============================] - 0s 36us/step - loss: 317.9076 - val_loss: 346.3350\n",
      "Epoch 208/300\n",
      "960/960 [==============================] - 0s 40us/step - loss: 317.8514 - val_loss: 346.2913\n",
      "Epoch 209/300\n",
      "960/960 [==============================] - 0s 49us/step - loss: 317.8236 - val_loss: 346.1012\n",
      "Epoch 210/300\n",
      "960/960 [==============================] - 0s 65us/step - loss: 317.8498 - val_loss: 345.8233\n",
      "Epoch 211/300\n",
      "960/960 [==============================] - 0s 39us/step - loss: 317.9621 - val_loss: 345.7847\n",
      "Epoch 212/300\n",
      "960/960 [==============================] - 0s 45us/step - loss: 317.9560 - val_loss: 346.2271\n",
      "Epoch 213/300\n",
      "960/960 [==============================] - 0s 29us/step - loss: 317.8361 - val_loss: 346.1287\n",
      "Epoch 214/300\n",
      "960/960 [==============================] - 0s 30us/step - loss: 317.9262 - val_loss: 346.1050\n",
      "Epoch 215/300\n",
      "960/960 [==============================] - 0s 47us/step - loss: 317.8316 - val_loss: 346.3387\n",
      "Epoch 216/300\n",
      "960/960 [==============================] - 0s 41us/step - loss: 317.8469 - val_loss: 346.2202\n",
      "Epoch 217/300\n",
      "960/960 [==============================] - 0s 53us/step - loss: 317.8286 - val_loss: 346.2938\n",
      "Epoch 218/300\n",
      "960/960 [==============================] - 0s 33us/step - loss: 317.8938 - val_loss: 346.0524\n",
      "Epoch 219/300\n",
      "960/960 [==============================] - 0s 46us/step - loss: 317.8899 - val_loss: 345.9938\n",
      "Epoch 220/300\n",
      "960/960 [==============================] - 0s 34us/step - loss: 317.8324 - val_loss: 346.2947\n",
      "Epoch 221/300\n",
      "960/960 [==============================] - 0s 32us/step - loss: 317.8520 - val_loss: 346.1938\n",
      "Epoch 222/300\n",
      "960/960 [==============================] - 0s 54us/step - loss: 317.8729 - val_loss: 346.3290\n",
      "Epoch 223/300\n",
      "960/960 [==============================] - 0s 47us/step - loss: 317.8605 - val_loss: 346.2345\n",
      "Epoch 224/300\n",
      "960/960 [==============================] - 0s 42us/step - loss: 317.8324 - val_loss: 346.2029\n",
      "Epoch 225/300\n",
      "960/960 [==============================] - 0s 35us/step - loss: 317.8729 - val_loss: 346.0496\n",
      "Epoch 226/300\n",
      "960/960 [==============================] - 0s 34us/step - loss: 317.8253 - val_loss: 346.2313\n",
      "Epoch 227/300\n",
      "960/960 [==============================] - 0s 58us/step - loss: 317.8307 - val_loss: 346.3008\n",
      "Epoch 228/300\n",
      "960/960 [==============================] - 0s 38us/step - loss: 317.8437 - val_loss: 346.2654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/300\n",
      "960/960 [==============================] - 0s 64us/step - loss: 317.8897 - val_loss: 346.3196\n",
      "Epoch 230/300\n",
      "960/960 [==============================] - 0s 32us/step - loss: 317.9295 - val_loss: 346.4416\n",
      "Epoch 231/300\n",
      "960/960 [==============================] - 0s 52us/step - loss: 317.8538 - val_loss: 346.1283\n",
      "Epoch 232/300\n",
      "960/960 [==============================] - 0s 38us/step - loss: 317.8966 - val_loss: 346.7230\n",
      "Epoch 233/300\n",
      "960/960 [==============================] - 0s 45us/step - loss: 317.8720 - val_loss: 346.3502\n",
      "Epoch 234/300\n",
      "960/960 [==============================] - 0s 51us/step - loss: 317.8892 - val_loss: 346.3580\n",
      "Epoch 235/300\n",
      "960/960 [==============================] - 0s 57us/step - loss: 317.8565 - val_loss: 346.1373\n",
      "Epoch 236/300\n",
      "960/960 [==============================] - 0s 41us/step - loss: 317.9593 - val_loss: 346.0998\n",
      "Epoch 237/300\n",
      "960/960 [==============================] - 0s 49us/step - loss: 317.8714 - val_loss: 346.3206\n",
      "Epoch 238/300\n",
      "960/960 [==============================] - 0s 41us/step - loss: 317.8200 - val_loss: 346.5628\n",
      "Epoch 239/300\n",
      "960/960 [==============================] - 0s 50us/step - loss: 317.8608 - val_loss: 346.3975\n",
      "Epoch 240/300\n",
      "960/960 [==============================] - 0s 39us/step - loss: 317.9163 - val_loss: 346.1796\n",
      "Epoch 241/300\n",
      "960/960 [==============================] - 0s 30us/step - loss: 317.8670 - val_loss: 345.9318\n",
      "Epoch 242/300\n",
      "960/960 [==============================] - 0s 49us/step - loss: 317.8770 - val_loss: 346.3063\n",
      "Epoch 243/300\n",
      "960/960 [==============================] - 0s 36us/step - loss: 317.8769 - val_loss: 346.5491\n",
      "Epoch 244/300\n",
      "960/960 [==============================] - 0s 31us/step - loss: 317.8639 - val_loss: 346.2715\n",
      "Epoch 245/300\n",
      "960/960 [==============================] - 0s 39us/step - loss: 317.9279 - val_loss: 346.3940\n",
      "Epoch 246/300\n",
      "960/960 [==============================] - 0s 41us/step - loss: 317.8905 - val_loss: 346.4955\n",
      "Epoch 247/300\n",
      "960/960 [==============================] - 0s 57us/step - loss: 317.9117 - val_loss: 346.3362\n",
      "Epoch 248/300\n",
      "960/960 [==============================] - 0s 37us/step - loss: 317.8847 - val_loss: 346.1312\n",
      "Epoch 249/300\n",
      "960/960 [==============================] - 0s 51us/step - loss: 318.0156 - val_loss: 346.0435\n",
      "Epoch 250/300\n",
      "960/960 [==============================] - 0s 27us/step - loss: 317.9273 - val_loss: 346.5474\n",
      "Epoch 251/300\n",
      "960/960 [==============================] - 0s 36us/step - loss: 317.8545 - val_loss: 346.2065\n",
      "Epoch 252/300\n",
      "960/960 [==============================] - 0s 48us/step - loss: 317.8124 - val_loss: 346.3175\n",
      "Epoch 253/300\n",
      "960/960 [==============================] - 0s 39us/step - loss: 318.0660 - val_loss: 346.2976\n",
      "Epoch 254/300\n",
      "960/960 [==============================] - 0s 50us/step - loss: 317.9229 - val_loss: 346.3504\n",
      "Epoch 255/300\n",
      "960/960 [==============================] - 0s 41us/step - loss: 317.9397 - val_loss: 346.7285\n",
      "Epoch 256/300\n",
      "960/960 [==============================] - 0s 56us/step - loss: 317.9097 - val_loss: 346.5322\n",
      "Epoch 257/300\n",
      "960/960 [==============================] - 0s 35us/step - loss: 317.9512 - val_loss: 346.1195\n",
      "Epoch 258/300\n",
      "960/960 [==============================] - 0s 35us/step - loss: 317.9078 - val_loss: 346.3132\n",
      "Epoch 259/300\n",
      "960/960 [==============================] - 0s 51us/step - loss: 317.9477 - val_loss: 346.4007\n",
      "Epoch 260/300\n",
      "960/960 [==============================] - 0s 39us/step - loss: 317.8855 - val_loss: 346.4226\n",
      "Epoch 261/300\n",
      "960/960 [==============================] - 0s 39us/step - loss: 317.8710 - val_loss: 346.3287\n",
      "Epoch 262/300\n",
      "960/960 [==============================] - 0s 31us/step - loss: 317.8671 - val_loss: 346.3293\n",
      "Epoch 263/300\n",
      "960/960 [==============================] - 0s 31us/step - loss: 317.8991 - val_loss: 346.5416\n",
      "Epoch 264/300\n",
      "960/960 [==============================] - 0s 45us/step - loss: 317.9222 - val_loss: 346.2521\n",
      "Epoch 265/300\n",
      "960/960 [==============================] - 0s 31us/step - loss: 317.9635 - val_loss: 346.6739\n",
      "Epoch 266/300\n",
      "960/960 [==============================] - 0s 36us/step - loss: 317.8588 - val_loss: 346.2928\n",
      "Epoch 267/300\n",
      "960/960 [==============================] - 0s 37us/step - loss: 318.0111 - val_loss: 345.9381\n",
      "Epoch 268/300\n",
      "960/960 [==============================] - 0s 34us/step - loss: 317.9383 - val_loss: 346.3214\n",
      "Epoch 269/300\n",
      "960/960 [==============================] - 0s 32us/step - loss: 317.9252 - val_loss: 346.7206\n",
      "Epoch 270/300\n",
      "960/960 [==============================] - 0s 49us/step - loss: 317.9026 - val_loss: 346.3427\n",
      "Epoch 271/300\n",
      "960/960 [==============================] - 0s 33us/step - loss: 317.9118 - val_loss: 346.1702\n",
      "Epoch 272/300\n",
      "960/960 [==============================] - 0s 46us/step - loss: 317.9986 - val_loss: 346.3078\n",
      "Epoch 273/300\n",
      "960/960 [==============================] - 0s 36us/step - loss: 317.9548 - val_loss: 346.7912\n",
      "Epoch 274/300\n",
      "960/960 [==============================] - 0s 36us/step - loss: 317.8229 - val_loss: 346.2621\n",
      "Epoch 275/300\n",
      "960/960 [==============================] - 0s 47us/step - loss: 317.9103 - val_loss: 346.6832\n",
      "Epoch 276/300\n",
      "960/960 [==============================] - 0s 39us/step - loss: 317.9070 - val_loss: 346.3700\n",
      "Epoch 277/300\n",
      "960/960 [==============================] - 0s 59us/step - loss: 317.9295 - val_loss: 346.3888\n",
      "Epoch 278/300\n",
      "960/960 [==============================] - 0s 30us/step - loss: 317.8727 - val_loss: 346.3478\n",
      "Epoch 279/300\n",
      "960/960 [==============================] - 0s 46us/step - loss: 317.9183 - val_loss: 346.5025\n",
      "Epoch 280/300\n",
      "960/960 [==============================] - 0s 30us/step - loss: 317.9591 - val_loss: 346.3708\n",
      "Epoch 281/300\n",
      "960/960 [==============================] - 0s 36us/step - loss: 317.9438 - val_loss: 346.1642\n",
      "Epoch 282/300\n",
      "960/960 [==============================] - 0s 40us/step - loss: 317.8769 - val_loss: 346.0737\n",
      "Epoch 283/300\n",
      "960/960 [==============================] - 0s 31us/step - loss: 317.9388 - val_loss: 346.6800\n",
      "Epoch 284/300\n",
      "960/960 [==============================] - 0s 28us/step - loss: 317.9626 - val_loss: 346.3673\n",
      "Epoch 285/300\n",
      "960/960 [==============================] - 0s 38us/step - loss: 317.8990 - val_loss: 346.3780\n",
      "Epoch 286/300\n",
      "960/960 [==============================] - 0s 30us/step - loss: 317.8756 - val_loss: 346.2075\n",
      "Epoch 287/300\n",
      "960/960 [==============================] - 0s 27us/step - loss: 317.9724 - val_loss: 346.6118\n",
      "Epoch 288/300\n",
      "960/960 [==============================] - 0s 43us/step - loss: 317.8637 - val_loss: 346.1054\n",
      "Epoch 289/300\n",
      "960/960 [==============================] - 0s 21us/step - loss: 317.9869 - val_loss: 346.2917\n",
      "Epoch 290/300\n",
      "960/960 [==============================] - 0s 26us/step - loss: 317.9347 - val_loss: 346.2477\n",
      "Epoch 291/300\n",
      "960/960 [==============================] - 0s 28us/step - loss: 317.9001 - val_loss: 346.2656\n",
      "Epoch 292/300\n",
      "960/960 [==============================] - 0s 33us/step - loss: 317.9301 - val_loss: 346.4988\n",
      "Epoch 293/300\n",
      "960/960 [==============================] - 0s 30us/step - loss: 317.9441 - val_loss: 346.2306\n",
      "Epoch 294/300\n",
      "960/960 [==============================] - 0s 26us/step - loss: 317.9745 - val_loss: 346.8339\n",
      "Epoch 295/300\n",
      "960/960 [==============================] - 0s 41us/step - loss: 317.8797 - val_loss: 346.1717\n",
      "Epoch 296/300\n",
      "960/960 [==============================] - 0s 33us/step - loss: 317.9664 - val_loss: 346.7620\n",
      "Epoch 297/300\n",
      "960/960 [==============================] - 0s 27us/step - loss: 318.0174 - val_loss: 346.0065\n",
      "Epoch 298/300\n",
      "960/960 [==============================] - 0s 50us/step - loss: 317.9040 - val_loss: 346.1454\n",
      "Epoch 299/300\n",
      "960/960 [==============================] - 0s 32us/step - loss: 317.8907 - val_loss: 346.1465\n",
      "Epoch 300/300\n",
      "960/960 [==============================] - 0s 30us/step - loss: 317.9492 - val_loss: 346.5690\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11f7b4860>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the neural network\n",
    "neuralModel.fit([trn.VISITOR_TEAM, trn.HOME_TEAM], trn.HOME_POINTS + trn.VISITOR_POINTS, batch_size=64, epochs=300, \n",
    "          validation_data=([val.VISITOR_TEAM, val.HOME_TEAM], val.HOME_POINTS + val.VISITOR_POINTS))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
